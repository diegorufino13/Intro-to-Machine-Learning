{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3mpwU57T9h7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Housing Data"
      ],
      "metadata": {
        "id": "9K_vgal4VJAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')\n",
        "file_path = '/content/drive/My Drive/Intro to ML/Housing.csv'\n",
        "housing = pd.DataFrame(pd.read_csv(file_path))\n",
        "# List of variables to map\n",
        "\n",
        "varlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "\n",
        "# Defining the map function\n",
        "def binary_map(x):\n",
        "    return x.map({'yes': 1, 'no': 0})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEX_AdKQUgAi",
        "outputId": "ff8d12b7-5106-4d8c-bb97-944d7d243a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housing[varlist] = housing[varlist].apply(binary_mapping)\n",
        "\n",
        "# Removing furnishingstatus column from housing\n",
        "housing = housing.drop('furnishingstatus', axis=1)\n",
        "\n",
        "# Removing price column from housing and making it its own data (y)\n",
        "y = housing.pop('price').values.reshape(-1,1)\n",
        "\n",
        "# Assigning the rest of the data to x\n",
        "x = housing.values"
      ],
      "metadata": {
        "id": "dUV5bGpnUDW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_n = torch.tensor(StandardScaler().fit_transform(x), dtype=torch.float32)\n",
        "y_n = torch.tensor(StandardScaler().fit_transform(y), dtype=torch.float32)\n",
        "\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_n, y_n, test_size=0.8, random_state=3)"
      ],
      "metadata": {
        "id": "x5Cj-BcPUFDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, x_train, x_valid, y_train, y_valid):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    housing_train = model(x_train)\n",
        "    loss_train = loss_fn(housing_train, y_train)\n",
        "\n",
        "    housing_valid = model(x_valid)\n",
        "    loss_val = loss_fn(housing_valid, y_valid)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "      print(f\"Epoch {epoch}. Training loss {loss_train.item()}, Validation loss {loss_val.item()}\")"
      ],
      "metadata": {
        "id": "fYcnHGvKUGwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1a"
      ],
      "metadata": {
        "id": "3loBC6LrYllT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden Layer 32\n",
        "seq_model = nn.Sequential(\n",
        "    nn.Linear(11, 32),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(32, 1))\n",
        "\n",
        "# RunningNN\n",
        "optimizer = optim.SGD(seq_model.parameters(), lr=.001)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    model = seq_model,\n",
        "    loss_fn = nn.MSELoss(),\n",
        "    x_train = x_train,\n",
        "    x_valid = x_valid,\n",
        "    y_train = y_train,\n",
        "    y_valid = y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGJhVqpsUIvO",
        "outputId": "9cc351aa-76e7-4d33-9e54-2aa061efdbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000. Training loss 0.41606447100639343, Validation loss 0.35657840967178345\n",
            "Epoch 2000. Training loss 0.3904227614402771, Validation loss 0.36776062846183777\n",
            "Epoch 3000. Training loss 0.3793689012527466, Validation loss 0.37048977613449097\n",
            "Epoch 4000. Training loss 0.37081965804100037, Validation loss 0.3709433972835541\n",
            "Epoch 5000. Training loss 0.3630216717720032, Validation loss 0.37065553665161133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1b"
      ],
      "metadata": {
        "id": "lP8MlXGuYhtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# size of layers are: 32, 64, 16\n",
        "seq_model = nn.Sequential(\n",
        "    nn.Linear(11, 32),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(32, 64),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(64, 16),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(16,1))\n",
        "\n",
        "# RunningNN\n",
        "\n",
        "optimizer = optim.SGD(seq_model.parameters(), lr=.001)\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    model = seq_model,\n",
        "    loss_fn = nn.MSELoss(),\n",
        "    x_train = x_train,\n",
        "    x_valid = x_valid,\n",
        "    y_train = y_train,\n",
        "    y_valid = y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmTMlCGxULpy",
        "outputId": "d959d0e5-0442-4741-aeab-5826a43f8134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000. Training loss 0.4699515700340271, Validation loss 0.34558790922164917\n",
            "Epoch 2000. Training loss 0.4216470718383789, Validation loss 0.3523559272289276\n",
            "Epoch 3000. Training loss 0.40006616711616516, Validation loss 0.3583272397518158\n",
            "Epoch 4000. Training loss 0.381867378950119, Validation loss 0.3603205978870392\n",
            "Epoch 5000. Training loss 0.36296945810317993, Validation loss 0.36064204573631287\n"
          ]
        }
      ]
    }
  ]
}