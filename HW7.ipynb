{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "Bvpa02KUoO0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries"
      ],
      "metadata": {
        "id": "kluRyaWNoSEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "torch.cuda.is_available()\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from torchvision import datasets\n",
        "import datetime"
      ],
      "metadata": {
        "id": "_3Jb7jloaoD6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEfdnpqgt337",
        "outputId": "8a64aefe-f990-4bd2-b398-499310770861"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Using GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9B5GeMCoXNv",
        "outputId": "504e4130-b994-4706-f367-cf5f83264820"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch7/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 41848233.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data-unversioned/p1ch7/cifar-10-python.tar.gz to ../data-unversioned/p1ch7/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "wAaNHErbqJuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = out.view(-1, 64 * 8 * 8)\n",
        "        out = self.act3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "OYAqhSJOoe6z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(cifar10, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(cifar10_val, batch_size=64, shuffle=False)\n",
        "\n",
        "def validate(model, loader, device):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs = imgs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += labels.shape[0]\n",
        "            correct += int((predicted == labels).sum())\n",
        "    model.train()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "keYdLU0IpK-p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader, device):\n",
        "    start_time = time.time()\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        val_accuracy = validate(model, val_loader, device) *100\n",
        "        avg_loss = loss_train / len(train_loader)\n",
        "        print(f\"Epoch: {epoch}, Training Loss: {avg_loss}\")\n",
        "        print(f'Validation Accuracy after epoch {epoch}: {val_accuracy}%')\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    print(f'Total Training Time: {duration} seconds')"
      ],
      "metadata": {
        "id": "2w5rLXFbphKz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "b0YKWR5Hp1bc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(\n",
        "    n_epochs=300,\n",
        "    optimizer=optimizer,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E31fuePqA2j",
        "outputId": "4057eeb6-5b4f-4a4e-a7b3-10704fc354a2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Training Loss: 2.096739678279213\n",
            "Validation Accuracy after epoch 1: 34.68%\n",
            "Epoch: 2, Training Loss: 1.7680414412027734\n",
            "Validation Accuracy after epoch 2: 40.06%\n",
            "Epoch: 3, Training Loss: 1.6244157139602524\n",
            "Validation Accuracy after epoch 3: 43.94%\n",
            "Epoch: 4, Training Loss: 1.537195571090864\n",
            "Validation Accuracy after epoch 4: 46.06%\n",
            "Epoch: 5, Training Loss: 1.4704386471482493\n",
            "Validation Accuracy after epoch 5: 48.44%\n",
            "Epoch: 6, Training Loss: 1.4133844704884093\n",
            "Validation Accuracy after epoch 6: 49.559999999999995%\n",
            "Epoch: 7, Training Loss: 1.3514177011102058\n",
            "Validation Accuracy after epoch 7: 53.33%\n",
            "Epoch: 8, Training Loss: 1.2950311509697028\n",
            "Validation Accuracy after epoch 8: 54.96%\n",
            "Epoch: 9, Training Loss: 1.2419594458454406\n",
            "Validation Accuracy after epoch 9: 50.56%\n",
            "Epoch: 10, Training Loss: 1.1926414908655465\n",
            "Validation Accuracy after epoch 10: 56.55%\n",
            "Epoch: 11, Training Loss: 1.1482998403289435\n",
            "Validation Accuracy after epoch 11: 58.4%\n",
            "Epoch: 12, Training Loss: 1.10719352609971\n",
            "Validation Accuracy after epoch 12: 57.730000000000004%\n",
            "Epoch: 13, Training Loss: 1.066903362036361\n",
            "Validation Accuracy after epoch 13: 54.17999999999999%\n",
            "Epoch: 14, Training Loss: 1.0321450428584653\n",
            "Validation Accuracy after epoch 14: 61.07%\n",
            "Epoch: 15, Training Loss: 0.9966631175002174\n",
            "Validation Accuracy after epoch 15: 60.260000000000005%\n",
            "Epoch: 16, Training Loss: 0.9645116371876749\n",
            "Validation Accuracy after epoch 16: 64.05%\n",
            "Epoch: 17, Training Loss: 0.9336034355261137\n",
            "Validation Accuracy after epoch 17: 64.16%\n",
            "Epoch: 18, Training Loss: 0.9078605392247515\n",
            "Validation Accuracy after epoch 18: 63.849999999999994%\n",
            "Epoch: 19, Training Loss: 0.8791993469990733\n",
            "Validation Accuracy after epoch 19: 65.60000000000001%\n",
            "Epoch: 20, Training Loss: 0.8548929899397408\n",
            "Validation Accuracy after epoch 20: 65.28%\n",
            "Epoch: 21, Training Loss: 0.8293703078385204\n",
            "Validation Accuracy after epoch 21: 67.13%\n",
            "Epoch: 22, Training Loss: 0.8060200973925993\n",
            "Validation Accuracy after epoch 22: 67.15%\n",
            "Epoch: 23, Training Loss: 0.7837029119281818\n",
            "Validation Accuracy after epoch 23: 67.08%\n",
            "Epoch: 24, Training Loss: 0.7597936945193259\n",
            "Validation Accuracy after epoch 24: 69.12%\n",
            "Epoch: 25, Training Loss: 0.7384582940879685\n",
            "Validation Accuracy after epoch 25: 68.03%\n",
            "Epoch: 26, Training Loss: 0.7182637008331011\n",
            "Validation Accuracy after epoch 26: 68.31%\n",
            "Epoch: 27, Training Loss: 0.6956362968210674\n",
            "Validation Accuracy after epoch 27: 65.64%\n",
            "Epoch: 28, Training Loss: 0.674818453200333\n",
            "Validation Accuracy after epoch 28: 68.94%\n",
            "Epoch: 29, Training Loss: 0.654866279619734\n",
            "Validation Accuracy after epoch 29: 70.55%\n",
            "Epoch: 30, Training Loss: 0.6345842909401335\n",
            "Validation Accuracy after epoch 30: 69.45%\n",
            "Epoch: 31, Training Loss: 0.613858447888928\n",
            "Validation Accuracy after epoch 31: 68.14%\n",
            "Epoch: 32, Training Loss: 0.5936013498650793\n",
            "Validation Accuracy after epoch 32: 70.47%\n",
            "Epoch: 33, Training Loss: 0.5745187433403166\n",
            "Validation Accuracy after epoch 33: 69.19999999999999%\n",
            "Epoch: 34, Training Loss: 0.5517735359690074\n",
            "Validation Accuracy after epoch 34: 68.84%\n",
            "Epoch: 35, Training Loss: 0.5321794986877295\n",
            "Validation Accuracy after epoch 35: 67.89%\n",
            "Epoch: 36, Training Loss: 0.5128592815240631\n",
            "Validation Accuracy after epoch 36: 67.58%\n",
            "Epoch: 37, Training Loss: 0.49119673212013587\n",
            "Validation Accuracy after epoch 37: 69.87%\n",
            "Epoch: 38, Training Loss: 0.47180870966152155\n",
            "Validation Accuracy after epoch 38: 69.27%\n",
            "Epoch: 39, Training Loss: 0.4528845581785797\n",
            "Validation Accuracy after epoch 39: 70.28999999999999%\n",
            "Epoch: 40, Training Loss: 0.43336806652109944\n",
            "Validation Accuracy after epoch 40: 71.93%\n",
            "Epoch: 41, Training Loss: 0.41488869694035374\n",
            "Validation Accuracy after epoch 41: 66.7%\n",
            "Epoch: 42, Training Loss: 0.39524001006961174\n",
            "Validation Accuracy after epoch 42: 71.54%\n",
            "Epoch: 43, Training Loss: 0.37629862722304774\n",
            "Validation Accuracy after epoch 43: 70.11%\n",
            "Epoch: 44, Training Loss: 0.35691024648868824\n",
            "Validation Accuracy after epoch 44: 71.11%\n",
            "Epoch: 45, Training Loss: 0.33992110392855257\n",
            "Validation Accuracy after epoch 45: 69.15%\n",
            "Epoch: 46, Training Loss: 0.32066614897278567\n",
            "Validation Accuracy after epoch 46: 70.32000000000001%\n",
            "Epoch: 47, Training Loss: 0.30430434945294316\n",
            "Validation Accuracy after epoch 47: 71.07%\n",
            "Epoch: 48, Training Loss: 0.2874383841881819\n",
            "Validation Accuracy after epoch 48: 71.33%\n",
            "Epoch: 49, Training Loss: 0.27102360150317095\n",
            "Validation Accuracy after epoch 49: 70.54%\n",
            "Epoch: 50, Training Loss: 0.25471933201298386\n",
            "Validation Accuracy after epoch 50: 70.25%\n",
            "Epoch: 51, Training Loss: 0.2404455895466573\n",
            "Validation Accuracy after epoch 51: 71.22%\n",
            "Epoch: 52, Training Loss: 0.2252421399954792\n",
            "Validation Accuracy after epoch 52: 71.13000000000001%\n",
            "Epoch: 53, Training Loss: 0.21040238436225736\n",
            "Validation Accuracy after epoch 53: 71.05%\n",
            "Epoch: 54, Training Loss: 0.1974624756466397\n",
            "Validation Accuracy after epoch 54: 70.99%\n",
            "Epoch: 55, Training Loss: 0.18448624586510232\n",
            "Validation Accuracy after epoch 55: 70.49%\n",
            "Epoch: 56, Training Loss: 0.17343951421587364\n",
            "Validation Accuracy after epoch 56: 70.11%\n",
            "Epoch: 57, Training Loss: 0.16099081377086738\n",
            "Validation Accuracy after epoch 57: 71.54%\n",
            "Epoch: 58, Training Loss: 0.15026918174627493\n",
            "Validation Accuracy after epoch 58: 71.75%\n",
            "Epoch: 59, Training Loss: 0.1405913153820483\n",
            "Validation Accuracy after epoch 59: 71.52%\n",
            "Epoch: 60, Training Loss: 0.13111073514708624\n",
            "Validation Accuracy after epoch 60: 71.45%\n",
            "Epoch: 61, Training Loss: 0.12214536296532434\n",
            "Validation Accuracy after epoch 61: 70.67999999999999%\n",
            "Epoch: 62, Training Loss: 0.11421387123367975\n",
            "Validation Accuracy after epoch 62: 70.25%\n",
            "Epoch: 63, Training Loss: 0.10641857713479977\n",
            "Validation Accuracy after epoch 63: 71.17999999999999%\n",
            "Epoch: 64, Training Loss: 0.09984646850953931\n",
            "Validation Accuracy after epoch 64: 71.24000000000001%\n",
            "Epoch: 65, Training Loss: 0.0928785108134646\n",
            "Validation Accuracy after epoch 65: 71.57%\n",
            "Epoch: 66, Training Loss: 0.08719819678408106\n",
            "Validation Accuracy after epoch 66: 71.69%\n",
            "Epoch: 67, Training Loss: 0.08172180334491955\n",
            "Validation Accuracy after epoch 67: 71.09%\n",
            "Epoch: 68, Training Loss: 0.07661469828556566\n",
            "Validation Accuracy after epoch 68: 71.56%\n",
            "Epoch: 69, Training Loss: 0.07193015187578586\n",
            "Validation Accuracy after epoch 69: 71.47%\n",
            "Epoch: 70, Training Loss: 0.06741556870605787\n",
            "Validation Accuracy after epoch 70: 71.67%\n",
            "Epoch: 71, Training Loss: 0.0638217956466062\n",
            "Validation Accuracy after epoch 71: 71.54%\n",
            "Epoch: 72, Training Loss: 0.06009445228921178\n",
            "Validation Accuracy after epoch 72: 71.35000000000001%\n",
            "Epoch: 73, Training Loss: 0.05681729997696398\n",
            "Validation Accuracy after epoch 73: 71.7%\n",
            "Epoch: 74, Training Loss: 0.05405939381588679\n",
            "Validation Accuracy after epoch 74: 71.67%\n",
            "Epoch: 75, Training Loss: 0.05112936200521639\n",
            "Validation Accuracy after epoch 75: 71.67%\n",
            "Epoch: 76, Training Loss: 0.048493269997675094\n",
            "Validation Accuracy after epoch 76: 71.5%\n",
            "Epoch: 77, Training Loss: 0.04616429730582877\n",
            "Validation Accuracy after epoch 77: 71.89999999999999%\n",
            "Epoch: 78, Training Loss: 0.04385345536129325\n",
            "Validation Accuracy after epoch 78: 71.73%\n",
            "Epoch: 79, Training Loss: 0.041803526849297765\n",
            "Validation Accuracy after epoch 79: 71.82%\n",
            "Epoch: 80, Training Loss: 0.03984200547370688\n",
            "Validation Accuracy after epoch 80: 71.73%\n",
            "Epoch: 81, Training Loss: 0.03829714410302355\n",
            "Validation Accuracy after epoch 81: 71.88%\n",
            "Epoch: 82, Training Loss: 0.03652987987651011\n",
            "Validation Accuracy after epoch 82: 71.8%\n",
            "Epoch: 83, Training Loss: 0.03505902672115037\n",
            "Validation Accuracy after epoch 83: 71.78999999999999%\n",
            "Epoch: 84, Training Loss: 0.033538368575827544\n",
            "Validation Accuracy after epoch 84: 71.71%\n",
            "Epoch: 85, Training Loss: 0.03226029003739281\n",
            "Validation Accuracy after epoch 85: 71.78999999999999%\n",
            "Epoch: 86, Training Loss: 0.031011960071409144\n",
            "Validation Accuracy after epoch 86: 71.77%\n",
            "Epoch: 87, Training Loss: 0.029857780441375034\n",
            "Validation Accuracy after epoch 87: 71.71%\n",
            "Epoch: 88, Training Loss: 0.02869421442317993\n",
            "Validation Accuracy after epoch 88: 71.81%\n",
            "Epoch: 89, Training Loss: 0.027598310972961698\n",
            "Validation Accuracy after epoch 89: 71.77%\n",
            "Epoch: 90, Training Loss: 0.026697964312227637\n",
            "Validation Accuracy after epoch 90: 71.73%\n",
            "Epoch: 91, Training Loss: 0.02586439813551543\n",
            "Validation Accuracy after epoch 91: 71.73%\n",
            "Epoch: 92, Training Loss: 0.024948356182450223\n",
            "Validation Accuracy after epoch 92: 71.69%\n",
            "Epoch: 93, Training Loss: 0.02412982126983726\n",
            "Validation Accuracy after epoch 93: 71.85000000000001%\n",
            "Epoch: 94, Training Loss: 0.02340648528021734\n",
            "Validation Accuracy after epoch 94: 71.77%\n",
            "Epoch: 95, Training Loss: 0.022670532333786072\n",
            "Validation Accuracy after epoch 95: 71.82%\n",
            "Epoch: 96, Training Loss: 0.02196889220143828\n",
            "Validation Accuracy after epoch 96: 71.81%\n",
            "Epoch: 97, Training Loss: 0.021274830641039192\n",
            "Validation Accuracy after epoch 97: 71.67%\n",
            "Epoch: 98, Training Loss: 0.02067335389311547\n",
            "Validation Accuracy after epoch 98: 71.94%\n",
            "Epoch: 99, Training Loss: 0.02014216811031751\n",
            "Validation Accuracy after epoch 99: 71.94%\n",
            "Epoch: 100, Training Loss: 0.019574550766488324\n",
            "Validation Accuracy after epoch 100: 71.88%\n",
            "Epoch: 101, Training Loss: 0.019002574766316758\n",
            "Validation Accuracy after epoch 101: 71.72%\n",
            "Epoch: 102, Training Loss: 0.018457380514067916\n",
            "Validation Accuracy after epoch 102: 71.94%\n",
            "Epoch: 103, Training Loss: 0.018009770173303154\n",
            "Validation Accuracy after epoch 103: 71.45%\n",
            "Epoch: 104, Training Loss: 0.017569841225119426\n",
            "Validation Accuracy after epoch 104: 72.02%\n",
            "Epoch: 105, Training Loss: 0.01710162757326613\n",
            "Validation Accuracy after epoch 105: 71.85000000000001%\n",
            "Epoch: 106, Training Loss: 0.016721338359996334\n",
            "Validation Accuracy after epoch 106: 71.8%\n",
            "Epoch: 107, Training Loss: 0.016286864664758104\n",
            "Validation Accuracy after epoch 107: 71.78%\n",
            "Epoch: 108, Training Loss: 0.01592854070989296\n",
            "Validation Accuracy after epoch 108: 71.98%\n",
            "Epoch: 109, Training Loss: 0.015534503872522993\n",
            "Validation Accuracy after epoch 109: 71.77%\n",
            "Epoch: 110, Training Loss: 0.015152723936940475\n",
            "Validation Accuracy after epoch 110: 71.91%\n",
            "Epoch: 111, Training Loss: 0.014845307149431285\n",
            "Validation Accuracy after epoch 111: 71.91%\n",
            "Epoch: 112, Training Loss: 0.014495301306905115\n",
            "Validation Accuracy after epoch 112: 71.78999999999999%\n",
            "Epoch: 113, Training Loss: 0.014203055690297537\n",
            "Validation Accuracy after epoch 113: 71.88%\n",
            "Epoch: 114, Training Loss: 0.01387242690953033\n",
            "Validation Accuracy after epoch 114: 71.77%\n",
            "Epoch: 115, Training Loss: 0.01360757306130017\n",
            "Validation Accuracy after epoch 115: 71.93%\n",
            "Epoch: 116, Training Loss: 0.01332208022351384\n",
            "Validation Accuracy after epoch 116: 71.93%\n",
            "Epoch: 117, Training Loss: 0.013023918132533502\n",
            "Validation Accuracy after epoch 117: 71.78999999999999%\n",
            "Epoch: 118, Training Loss: 0.01279350583050924\n",
            "Validation Accuracy after epoch 118: 71.95%\n",
            "Epoch: 119, Training Loss: 0.012485040390454328\n",
            "Validation Accuracy after epoch 119: 71.95%\n",
            "Epoch: 120, Training Loss: 0.012288315240722483\n",
            "Validation Accuracy after epoch 120: 71.95%\n",
            "Epoch: 121, Training Loss: 0.012055296355577382\n",
            "Validation Accuracy after epoch 121: 71.89999999999999%\n",
            "Epoch: 122, Training Loss: 0.011808591586349488\n",
            "Validation Accuracy after epoch 122: 71.84%\n",
            "Epoch: 123, Training Loss: 0.011586758349200381\n",
            "Validation Accuracy after epoch 123: 71.93%\n",
            "Epoch: 124, Training Loss: 0.011396375727122817\n",
            "Validation Accuracy after epoch 124: 71.83%\n",
            "Epoch: 125, Training Loss: 0.01117919162487435\n",
            "Validation Accuracy after epoch 125: 71.91%\n",
            "Epoch: 126, Training Loss: 0.010973462734319022\n",
            "Validation Accuracy after epoch 126: 71.92%\n",
            "Epoch: 127, Training Loss: 0.010789275651111666\n",
            "Validation Accuracy after epoch 127: 72.03%\n",
            "Epoch: 128, Training Loss: 0.010601664365738478\n",
            "Validation Accuracy after epoch 128: 71.95%\n",
            "Epoch: 129, Training Loss: 0.010425199387128206\n",
            "Validation Accuracy after epoch 129: 71.99%\n",
            "Epoch: 130, Training Loss: 0.010239192535338537\n",
            "Validation Accuracy after epoch 130: 71.88%\n",
            "Epoch: 131, Training Loss: 0.010097265572827833\n",
            "Validation Accuracy after epoch 131: 71.85000000000001%\n",
            "Epoch: 132, Training Loss: 0.009931121185860214\n",
            "Validation Accuracy after epoch 132: 71.83%\n",
            "Epoch: 133, Training Loss: 0.009760633069316826\n",
            "Validation Accuracy after epoch 133: 71.82%\n",
            "Epoch: 134, Training Loss: 0.009603667363543492\n",
            "Validation Accuracy after epoch 134: 71.87%\n",
            "Epoch: 135, Training Loss: 0.009436881077973663\n",
            "Validation Accuracy after epoch 135: 71.88%\n",
            "Epoch: 136, Training Loss: 0.00931123483097157\n",
            "Validation Accuracy after epoch 136: 71.96000000000001%\n",
            "Epoch: 137, Training Loss: 0.009165090584979795\n",
            "Validation Accuracy after epoch 137: 71.91%\n",
            "Epoch: 138, Training Loss: 0.009023369729395032\n",
            "Validation Accuracy after epoch 138: 71.78999999999999%\n",
            "Epoch: 139, Training Loss: 0.008887619694189913\n",
            "Validation Accuracy after epoch 139: 71.81%\n",
            "Epoch: 140, Training Loss: 0.008772486766033313\n",
            "Validation Accuracy after epoch 140: 71.74000000000001%\n",
            "Epoch: 141, Training Loss: 0.008649998925068913\n",
            "Validation Accuracy after epoch 141: 71.8%\n",
            "Epoch: 142, Training Loss: 0.008502426218417713\n",
            "Validation Accuracy after epoch 142: 71.89%\n",
            "Epoch: 143, Training Loss: 0.008389753416952346\n",
            "Validation Accuracy after epoch 143: 71.96000000000001%\n",
            "Epoch: 144, Training Loss: 0.008262039055033109\n",
            "Validation Accuracy after epoch 144: 71.89%\n",
            "Epoch: 145, Training Loss: 0.008170788146584007\n",
            "Validation Accuracy after epoch 145: 71.8%\n",
            "Epoch: 146, Training Loss: 0.008024117727156567\n",
            "Validation Accuracy after epoch 146: 71.93%\n",
            "Epoch: 147, Training Loss: 0.007924388095503077\n",
            "Validation Accuracy after epoch 147: 71.87%\n",
            "Epoch: 148, Training Loss: 0.00781827436074081\n",
            "Validation Accuracy after epoch 148: 71.93%\n",
            "Epoch: 149, Training Loss: 0.0077067948717033236\n",
            "Validation Accuracy after epoch 149: 71.93%\n",
            "Epoch: 150, Training Loss: 0.007612825766720278\n",
            "Validation Accuracy after epoch 150: 71.85000000000001%\n",
            "Epoch: 151, Training Loss: 0.007517929980293145\n",
            "Validation Accuracy after epoch 151: 71.89999999999999%\n",
            "Epoch: 152, Training Loss: 0.007418107012134341\n",
            "Validation Accuracy after epoch 152: 71.78999999999999%\n",
            "Epoch: 153, Training Loss: 0.0073186304614357555\n",
            "Validation Accuracy after epoch 153: 71.86%\n",
            "Epoch: 154, Training Loss: 0.007236329784445331\n",
            "Validation Accuracy after epoch 154: 71.87%\n",
            "Epoch: 155, Training Loss: 0.007133430731065971\n",
            "Validation Accuracy after epoch 155: 71.92%\n",
            "Epoch: 156, Training Loss: 0.00704544522951993\n",
            "Validation Accuracy after epoch 156: 71.86%\n",
            "Epoch: 157, Training Loss: 0.006966157997970271\n",
            "Validation Accuracy after epoch 157: 71.84%\n",
            "Epoch: 158, Training Loss: 0.0068827743327621455\n",
            "Validation Accuracy after epoch 158: 71.87%\n",
            "Epoch: 159, Training Loss: 0.006801115158383194\n",
            "Validation Accuracy after epoch 159: 71.96000000000001%\n",
            "Epoch: 160, Training Loss: 0.006719423512763837\n",
            "Validation Accuracy after epoch 160: 71.87%\n",
            "Epoch: 161, Training Loss: 0.006630607491806911\n",
            "Validation Accuracy after epoch 161: 71.86%\n",
            "Epoch: 162, Training Loss: 0.006563849422647177\n",
            "Validation Accuracy after epoch 162: 71.84%\n",
            "Epoch: 163, Training Loss: 0.0064805835462234855\n",
            "Validation Accuracy after epoch 163: 71.86%\n",
            "Epoch: 164, Training Loss: 0.006409469541743436\n",
            "Validation Accuracy after epoch 164: 71.82%\n",
            "Epoch: 165, Training Loss: 0.006339555775063098\n",
            "Validation Accuracy after epoch 165: 71.73%\n",
            "Epoch: 166, Training Loss: 0.006266559313987489\n",
            "Validation Accuracy after epoch 166: 71.85000000000001%\n",
            "Epoch: 167, Training Loss: 0.006199753678896848\n",
            "Validation Accuracy after epoch 167: 71.87%\n",
            "Epoch: 168, Training Loss: 0.006131174994985123\n",
            "Validation Accuracy after epoch 168: 71.81%\n",
            "Epoch: 169, Training Loss: 0.006061803493255754\n",
            "Validation Accuracy after epoch 169: 71.78999999999999%\n",
            "Epoch: 170, Training Loss: 0.006006713730611783\n",
            "Validation Accuracy after epoch 170: 71.82%\n",
            "Epoch: 171, Training Loss: 0.005931600174137756\n",
            "Validation Accuracy after epoch 171: 71.89%\n",
            "Epoch: 172, Training Loss: 0.005870548416348293\n",
            "Validation Accuracy after epoch 172: 71.78999999999999%\n",
            "Epoch: 173, Training Loss: 0.005815139472070138\n",
            "Validation Accuracy after epoch 173: 71.96000000000001%\n",
            "Epoch: 174, Training Loss: 0.0057428403036392595\n",
            "Validation Accuracy after epoch 174: 71.82%\n",
            "Epoch: 175, Training Loss: 0.005686210461861223\n",
            "Validation Accuracy after epoch 175: 71.72%\n",
            "Epoch: 176, Training Loss: 0.0056332619056877345\n",
            "Validation Accuracy after epoch 176: 71.86%\n",
            "Epoch: 177, Training Loss: 0.005574746916363554\n",
            "Validation Accuracy after epoch 177: 71.81%\n",
            "Epoch: 178, Training Loss: 0.005514030630016685\n",
            "Validation Accuracy after epoch 178: 71.76%\n",
            "Epoch: 179, Training Loss: 0.005459727319267095\n",
            "Validation Accuracy after epoch 179: 71.85000000000001%\n",
            "Epoch: 180, Training Loss: 0.005403547922013532\n",
            "Validation Accuracy after epoch 180: 71.81%\n",
            "Epoch: 181, Training Loss: 0.005351367013533707\n",
            "Validation Accuracy after epoch 181: 71.76%\n",
            "Epoch: 182, Training Loss: 0.005290888494316517\n",
            "Validation Accuracy after epoch 182: 71.83%\n",
            "Epoch: 183, Training Loss: 0.005250196443642001\n",
            "Validation Accuracy after epoch 183: 71.8%\n",
            "Epoch: 184, Training Loss: 0.005202626964896727\n",
            "Validation Accuracy after epoch 184: 71.82%\n",
            "Epoch: 185, Training Loss: 0.005145647191166249\n",
            "Validation Accuracy after epoch 185: 71.8%\n",
            "Epoch: 186, Training Loss: 0.005102020445401254\n",
            "Validation Accuracy after epoch 186: 71.87%\n",
            "Epoch: 187, Training Loss: 0.005056343822027831\n",
            "Validation Accuracy after epoch 187: 71.78999999999999%\n",
            "Epoch: 188, Training Loss: 0.005002671289388709\n",
            "Validation Accuracy after epoch 188: 71.86%\n",
            "Epoch: 189, Training Loss: 0.00495823232970341\n",
            "Validation Accuracy after epoch 189: 71.83%\n",
            "Epoch: 190, Training Loss: 0.004911592038160147\n",
            "Validation Accuracy after epoch 190: 71.8%\n",
            "Epoch: 191, Training Loss: 0.004860003965625735\n",
            "Validation Accuracy after epoch 191: 71.82%\n",
            "Epoch: 192, Training Loss: 0.004822211850987143\n",
            "Validation Accuracy after epoch 192: 71.88%\n",
            "Epoch: 193, Training Loss: 0.004779543560010183\n",
            "Validation Accuracy after epoch 193: 71.85000000000001%\n",
            "Epoch: 194, Training Loss: 0.004741943891510329\n",
            "Validation Accuracy after epoch 194: 71.71%\n",
            "Epoch: 195, Training Loss: 0.004696176723515153\n",
            "Validation Accuracy after epoch 195: 71.78999999999999%\n",
            "Epoch: 196, Training Loss: 0.004655003277918376\n",
            "Validation Accuracy after epoch 196: 71.72%\n",
            "Epoch: 197, Training Loss: 0.004613002386156117\n",
            "Validation Accuracy after epoch 197: 71.81%\n",
            "Epoch: 198, Training Loss: 0.004574638968536064\n",
            "Validation Accuracy after epoch 198: 71.78999999999999%\n",
            "Epoch: 199, Training Loss: 0.004537931917940298\n",
            "Validation Accuracy after epoch 199: 71.74000000000001%\n",
            "Epoch: 200, Training Loss: 0.0044949553201875415\n",
            "Validation Accuracy after epoch 200: 71.89%\n",
            "Epoch: 201, Training Loss: 0.004451712671443439\n",
            "Validation Accuracy after epoch 201: 71.87%\n",
            "Epoch: 202, Training Loss: 0.004425483043877232\n",
            "Validation Accuracy after epoch 202: 71.87%\n",
            "Epoch: 203, Training Loss: 0.004389576231310492\n",
            "Validation Accuracy after epoch 203: 71.85000000000001%\n",
            "Epoch: 204, Training Loss: 0.0043485014329609625\n",
            "Validation Accuracy after epoch 204: 71.81%\n",
            "Epoch: 205, Training Loss: 0.004309283552186378\n",
            "Validation Accuracy after epoch 205: 71.81%\n",
            "Epoch: 206, Training Loss: 0.004277899840791874\n",
            "Validation Accuracy after epoch 206: 71.87%\n",
            "Epoch: 207, Training Loss: 0.004240532440509733\n",
            "Validation Accuracy after epoch 207: 71.81%\n",
            "Epoch: 208, Training Loss: 0.004211212269595021\n",
            "Validation Accuracy after epoch 208: 71.73%\n",
            "Epoch: 209, Training Loss: 0.0041722541253970905\n",
            "Validation Accuracy after epoch 209: 71.89%\n",
            "Epoch: 210, Training Loss: 0.00414225347834351\n",
            "Validation Accuracy after epoch 210: 71.86%\n",
            "Epoch: 211, Training Loss: 0.0041082546453151255\n",
            "Validation Accuracy after epoch 211: 71.82%\n",
            "Epoch: 212, Training Loss: 0.0040785464320612875\n",
            "Validation Accuracy after epoch 212: 71.87%\n",
            "Epoch: 213, Training Loss: 0.004045193969353061\n",
            "Validation Accuracy after epoch 213: 71.7%\n",
            "Epoch: 214, Training Loss: 0.004012903279286649\n",
            "Validation Accuracy after epoch 214: 71.86%\n",
            "Epoch: 215, Training Loss: 0.00398384038921055\n",
            "Validation Accuracy after epoch 215: 71.86%\n",
            "Epoch: 216, Training Loss: 0.003951771651356555\n",
            "Validation Accuracy after epoch 216: 71.83%\n",
            "Epoch: 217, Training Loss: 0.003918178266395464\n",
            "Validation Accuracy after epoch 217: 71.76%\n",
            "Epoch: 218, Training Loss: 0.0038904470675613\n",
            "Validation Accuracy after epoch 218: 71.78%\n",
            "Epoch: 219, Training Loss: 0.0038631784883292053\n",
            "Validation Accuracy after epoch 219: 71.82%\n",
            "Epoch: 220, Training Loss: 0.0038302456406290497\n",
            "Validation Accuracy after epoch 220: 71.83%\n",
            "Epoch: 221, Training Loss: 0.0038081540680273683\n",
            "Validation Accuracy after epoch 221: 71.89%\n",
            "Epoch: 222, Training Loss: 0.003777573736386893\n",
            "Validation Accuracy after epoch 222: 71.78999999999999%\n",
            "Epoch: 223, Training Loss: 0.0037482837393708395\n",
            "Validation Accuracy after epoch 223: 71.78999999999999%\n",
            "Epoch: 224, Training Loss: 0.0037256303544649307\n",
            "Validation Accuracy after epoch 224: 71.83%\n",
            "Epoch: 225, Training Loss: 0.003698691815796458\n",
            "Validation Accuracy after epoch 225: 71.86%\n",
            "Epoch: 226, Training Loss: 0.0036693095382007643\n",
            "Validation Accuracy after epoch 226: 71.76%\n",
            "Epoch: 227, Training Loss: 0.0036469820316385507\n",
            "Validation Accuracy after epoch 227: 71.82%\n",
            "Epoch: 228, Training Loss: 0.0036188729599837565\n",
            "Validation Accuracy after epoch 228: 71.82%\n",
            "Epoch: 229, Training Loss: 0.0035934664430799404\n",
            "Validation Accuracy after epoch 229: 71.87%\n",
            "Epoch: 230, Training Loss: 0.003569987203266062\n",
            "Validation Accuracy after epoch 230: 71.77%\n",
            "Epoch: 231, Training Loss: 0.0035412348273908124\n",
            "Validation Accuracy after epoch 231: 71.86%\n",
            "Epoch: 232, Training Loss: 0.003519353915013068\n",
            "Validation Accuracy after epoch 232: 71.76%\n",
            "Epoch: 233, Training Loss: 0.0034933351751421688\n",
            "Validation Accuracy after epoch 233: 71.77%\n",
            "Epoch: 234, Training Loss: 0.003468089414548481\n",
            "Validation Accuracy after epoch 234: 71.82%\n",
            "Epoch: 235, Training Loss: 0.003450233393999012\n",
            "Validation Accuracy after epoch 235: 71.8%\n",
            "Epoch: 236, Training Loss: 0.003421588174110312\n",
            "Validation Accuracy after epoch 236: 71.77%\n",
            "Epoch: 237, Training Loss: 0.003402038824969612\n",
            "Validation Accuracy after epoch 237: 71.84%\n",
            "Epoch: 238, Training Loss: 0.0033763090379016897\n",
            "Validation Accuracy after epoch 238: 71.8%\n",
            "Epoch: 239, Training Loss: 0.0033565234427716667\n",
            "Validation Accuracy after epoch 239: 71.83%\n",
            "Epoch: 240, Training Loss: 0.0033320180275013\n",
            "Validation Accuracy after epoch 240: 71.83%\n",
            "Epoch: 241, Training Loss: 0.0033113910044576794\n",
            "Validation Accuracy after epoch 241: 71.84%\n",
            "Epoch: 242, Training Loss: 0.0032884527682302913\n",
            "Validation Accuracy after epoch 242: 71.77%\n",
            "Epoch: 243, Training Loss: 0.0032661335271559275\n",
            "Validation Accuracy after epoch 243: 71.87%\n",
            "Epoch: 244, Training Loss: 0.0032453642798709157\n",
            "Validation Accuracy after epoch 244: 71.87%\n",
            "Epoch: 245, Training Loss: 0.003228465852606327\n",
            "Validation Accuracy after epoch 245: 71.88%\n",
            "Epoch: 246, Training Loss: 0.003203261153125788\n",
            "Validation Accuracy after epoch 246: 71.81%\n",
            "Epoch: 247, Training Loss: 0.003185065258788588\n",
            "Validation Accuracy after epoch 247: 71.88%\n",
            "Epoch: 248, Training Loss: 0.0031621829738192582\n",
            "Validation Accuracy after epoch 248: 71.78%\n",
            "Epoch: 249, Training Loss: 0.003143941311438418\n",
            "Validation Accuracy after epoch 249: 71.93%\n",
            "Epoch: 250, Training Loss: 0.0031242589839934214\n",
            "Validation Accuracy after epoch 250: 71.77%\n",
            "Epoch: 251, Training Loss: 0.0031031642705821394\n",
            "Validation Accuracy after epoch 251: 71.87%\n",
            "Epoch: 252, Training Loss: 0.0030843439497663387\n",
            "Validation Accuracy after epoch 252: 71.78999999999999%\n",
            "Epoch: 253, Training Loss: 0.003067012731720696\n",
            "Validation Accuracy after epoch 253: 71.81%\n",
            "Epoch: 254, Training Loss: 0.003045895073028124\n",
            "Validation Accuracy after epoch 254: 71.75%\n",
            "Epoch: 255, Training Loss: 0.0030283468276443306\n",
            "Validation Accuracy after epoch 255: 71.78%\n",
            "Epoch: 256, Training Loss: 0.0030102662190132777\n",
            "Validation Accuracy after epoch 256: 71.87%\n",
            "Epoch: 257, Training Loss: 0.0029925214778155546\n",
            "Validation Accuracy after epoch 257: 71.76%\n",
            "Epoch: 258, Training Loss: 0.0029759628896522897\n",
            "Validation Accuracy after epoch 258: 71.77%\n",
            "Epoch: 259, Training Loss: 0.0029565746139120453\n",
            "Validation Accuracy after epoch 259: 71.82%\n",
            "Epoch: 260, Training Loss: 0.002940625725838039\n",
            "Validation Accuracy after epoch 260: 71.76%\n",
            "Epoch: 261, Training Loss: 0.002920612526248874\n",
            "Validation Accuracy after epoch 261: 71.83%\n",
            "Epoch: 262, Training Loss: 0.002905181832248321\n",
            "Validation Accuracy after epoch 262: 71.86%\n",
            "Epoch: 263, Training Loss: 0.0028859827343834196\n",
            "Validation Accuracy after epoch 263: 71.82%\n",
            "Epoch: 264, Training Loss: 0.002870778204686225\n",
            "Validation Accuracy after epoch 264: 71.84%\n",
            "Epoch: 265, Training Loss: 0.0028537668072192183\n",
            "Validation Accuracy after epoch 265: 71.78%\n",
            "Epoch: 266, Training Loss: 0.002835675307651958\n",
            "Validation Accuracy after epoch 266: 71.75%\n",
            "Epoch: 267, Training Loss: 0.002822829887557946\n",
            "Validation Accuracy after epoch 267: 71.89%\n",
            "Epoch: 268, Training Loss: 0.002804265517736678\n",
            "Validation Accuracy after epoch 268: 71.76%\n",
            "Epoch: 269, Training Loss: 0.0027885446365139045\n",
            "Validation Accuracy after epoch 269: 71.81%\n",
            "Epoch: 270, Training Loss: 0.002773229573148272\n",
            "Validation Accuracy after epoch 270: 71.81%\n",
            "Epoch: 271, Training Loss: 0.0027582812286160714\n",
            "Validation Accuracy after epoch 271: 71.83%\n",
            "Epoch: 272, Training Loss: 0.0027406269339356297\n",
            "Validation Accuracy after epoch 272: 71.86%\n",
            "Epoch: 273, Training Loss: 0.0027275090809980563\n",
            "Validation Accuracy after epoch 273: 71.82%\n",
            "Epoch: 274, Training Loss: 0.0027122698313987734\n",
            "Validation Accuracy after epoch 274: 71.91%\n",
            "Epoch: 275, Training Loss: 0.0026982803098068993\n",
            "Validation Accuracy after epoch 275: 71.83%\n",
            "Epoch: 276, Training Loss: 0.00268291158523039\n",
            "Validation Accuracy after epoch 276: 71.89999999999999%\n",
            "Epoch: 277, Training Loss: 0.002667004513927042\n",
            "Validation Accuracy after epoch 277: 71.78%\n",
            "Epoch: 278, Training Loss: 0.0026540252479219624\n",
            "Validation Accuracy after epoch 278: 71.73%\n",
            "Epoch: 279, Training Loss: 0.0026370492785254404\n",
            "Validation Accuracy after epoch 279: 71.78999999999999%\n",
            "Epoch: 280, Training Loss: 0.0026227401956842016\n",
            "Validation Accuracy after epoch 280: 71.91%\n",
            "Epoch: 281, Training Loss: 0.0026108272825641665\n",
            "Validation Accuracy after epoch 281: 71.75%\n",
            "Epoch: 282, Training Loss: 0.002595918900047517\n",
            "Validation Accuracy after epoch 282: 71.75%\n",
            "Epoch: 283, Training Loss: 0.002582175657599736\n",
            "Validation Accuracy after epoch 283: 71.81%\n",
            "Epoch: 284, Training Loss: 0.0025689399485890768\n",
            "Validation Accuracy after epoch 284: 71.89%\n",
            "Epoch: 285, Training Loss: 0.002553808956306971\n",
            "Validation Accuracy after epoch 285: 71.78%\n",
            "Epoch: 286, Training Loss: 0.002542236272324248\n",
            "Validation Accuracy after epoch 286: 71.88%\n",
            "Epoch: 287, Training Loss: 0.0025272561164865807\n",
            "Validation Accuracy after epoch 287: 71.83%\n",
            "Epoch: 288, Training Loss: 0.002516793994777276\n",
            "Validation Accuracy after epoch 288: 71.85000000000001%\n",
            "Epoch: 289, Training Loss: 0.0025029025154302605\n",
            "Validation Accuracy after epoch 289: 71.76%\n",
            "Epoch: 290, Training Loss: 0.0024908161967756976\n",
            "Validation Accuracy after epoch 290: 71.82%\n",
            "Epoch: 291, Training Loss: 0.0024759990509713777\n",
            "Validation Accuracy after epoch 291: 71.8%\n",
            "Epoch: 292, Training Loss: 0.0024635110288927487\n",
            "Validation Accuracy after epoch 292: 71.89999999999999%\n",
            "Epoch: 293, Training Loss: 0.0024502305575953725\n",
            "Validation Accuracy after epoch 293: 71.8%\n",
            "Epoch: 294, Training Loss: 0.00243963316411061\n",
            "Validation Accuracy after epoch 294: 71.83%\n",
            "Epoch: 295, Training Loss: 0.002425672751112991\n",
            "Validation Accuracy after epoch 295: 71.86%\n",
            "Epoch: 296, Training Loss: 0.002415475544973474\n",
            "Validation Accuracy after epoch 296: 71.93%\n",
            "Epoch: 297, Training Loss: 0.002403505238355435\n",
            "Validation Accuracy after epoch 297: 71.85000000000001%\n",
            "Epoch: 298, Training Loss: 0.002390292144733031\n",
            "Validation Accuracy after epoch 298: 71.87%\n",
            "Epoch: 299, Training Loss: 0.00237731024449634\n",
            "Validation Accuracy after epoch 299: 71.76%\n",
            "Epoch: 300, Training Loss: 0.002365985431957304\n",
            "Validation Accuracy after epoch 300: 71.85000000000001%\n",
            "Total Training Time: 10.895477056503296 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# adding one more additional convolution layer followed by an activation function and pooling function"
      ],
      "metadata": {
        "id": "1Fabjf-i8QBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader, device):\n",
        "    start_time = time.time()\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        val_accuracy = validate(model, val_loader, device) *100\n",
        "        avg_loss = loss_train / len(train_loader)\n",
        "        print(f\"Epoch: {epoch}, Training Loss: {avg_loss}\")\n",
        "        print(f'Validation Accuracy after epoch {epoch}: {val_accuracy}%')\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    print(f'Total Training Time: {duration} seconds')"
      ],
      "metadata": {
        "id": "ad-rfht-BRX2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.act4 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = self.pool3(self.act3(self.conv3(out)))\n",
        "        out = out.view(-1, 128 * 4 * 4)\n",
        "        out = self.act4(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "hBUmJ2c9BlWC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Om02IZFhA1nU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(\n",
        "    n_epochs=300,\n",
        "    optimizer=optimizer,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfhk4rr-93E6",
        "outputId": "2c0d74a2-65d5-4455-c7ad-ac1ab088f8d5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Training Loss: 2.202404294172516\n",
            "Validation Accuracy after epoch 1: 25.790000000000003%\n",
            "Epoch: 2, Training Loss: 1.9527263124580578\n",
            "Validation Accuracy after epoch 2: 34.300000000000004%\n",
            "Epoch: 3, Training Loss: 1.7619632994732284\n",
            "Validation Accuracy after epoch 3: 40.839999999999996%\n",
            "Epoch: 4, Training Loss: 1.6130900483607027\n",
            "Validation Accuracy after epoch 4: 42.38%\n",
            "Epoch: 5, Training Loss: 1.5178910172199045\n",
            "Validation Accuracy after epoch 5: 47.53%\n",
            "Epoch: 6, Training Loss: 1.4407366872443568\n",
            "Validation Accuracy after epoch 6: 49.8%\n",
            "Epoch: 7, Training Loss: 1.372091787702897\n",
            "Validation Accuracy after epoch 7: 51.68000000000001%\n",
            "Epoch: 8, Training Loss: 1.313078278165949\n",
            "Validation Accuracy after epoch 8: 52.290000000000006%\n",
            "Epoch: 9, Training Loss: 1.2568415203667662\n",
            "Validation Accuracy after epoch 9: 55.559999999999995%\n",
            "Epoch: 10, Training Loss: 1.2042441405451205\n",
            "Validation Accuracy after epoch 10: 58.620000000000005%\n",
            "Epoch: 11, Training Loss: 1.1530508490474634\n",
            "Validation Accuracy after epoch 11: 59.35%\n",
            "Epoch: 12, Training Loss: 1.1043780150315952\n",
            "Validation Accuracy after epoch 12: 58.52%\n",
            "Epoch: 13, Training Loss: 1.0625529372326248\n",
            "Validation Accuracy after epoch 13: 59.150000000000006%\n",
            "Epoch: 14, Training Loss: 1.0246076224862462\n",
            "Validation Accuracy after epoch 14: 62.77%\n",
            "Epoch: 15, Training Loss: 0.9899654609467977\n",
            "Validation Accuracy after epoch 15: 63.17%\n",
            "Epoch: 16, Training Loss: 0.9558535725106974\n",
            "Validation Accuracy after epoch 16: 64.22%\n",
            "Epoch: 17, Training Loss: 0.9262480112292882\n",
            "Validation Accuracy after epoch 17: 65.53999999999999%\n",
            "Epoch: 18, Training Loss: 0.8984942923269004\n",
            "Validation Accuracy after epoch 18: 66.42%\n",
            "Epoch: 19, Training Loss: 0.8723766051442422\n",
            "Validation Accuracy after epoch 19: 66.46%\n",
            "Epoch: 20, Training Loss: 0.8490089098815723\n",
            "Validation Accuracy after epoch 20: 65.68%\n",
            "Epoch: 21, Training Loss: 0.8232689706794442\n",
            "Validation Accuracy after epoch 21: 66.84%\n",
            "Epoch: 22, Training Loss: 0.80136049609355\n",
            "Validation Accuracy after epoch 22: 67.16%\n",
            "Epoch: 23, Training Loss: 0.7780263465078895\n",
            "Validation Accuracy after epoch 23: 68.38%\n",
            "Epoch: 24, Training Loss: 0.7572631794778283\n",
            "Validation Accuracy after epoch 24: 69.15%\n",
            "Epoch: 25, Training Loss: 0.7358697413483544\n",
            "Validation Accuracy after epoch 25: 68.81%\n",
            "Epoch: 26, Training Loss: 0.7146801377272667\n",
            "Validation Accuracy after epoch 26: 70.03%\n",
            "Epoch: 27, Training Loss: 0.6962996888191194\n",
            "Validation Accuracy after epoch 27: 68.54%\n",
            "Epoch: 28, Training Loss: 0.6782960436685616\n",
            "Validation Accuracy after epoch 28: 70.62%\n",
            "Epoch: 29, Training Loss: 0.6576525814392987\n",
            "Validation Accuracy after epoch 29: 69.51%\n",
            "Epoch: 30, Training Loss: 0.6394537737226242\n",
            "Validation Accuracy after epoch 30: 71.19%\n",
            "Epoch: 31, Training Loss: 0.620513336509085\n",
            "Validation Accuracy after epoch 31: 68.06%\n",
            "Epoch: 32, Training Loss: 0.6024877759425536\n",
            "Validation Accuracy after epoch 32: 69.15%\n",
            "Epoch: 33, Training Loss: 0.5872167256634558\n",
            "Validation Accuracy after epoch 33: 71.46000000000001%\n",
            "Epoch: 34, Training Loss: 0.5694064905347727\n",
            "Validation Accuracy after epoch 34: 71.69%\n",
            "Epoch: 35, Training Loss: 0.5523070526473662\n",
            "Validation Accuracy after epoch 35: 69.43%\n",
            "Epoch: 36, Training Loss: 0.5345094271023255\n",
            "Validation Accuracy after epoch 36: 71.28%\n",
            "Epoch: 37, Training Loss: 0.5175151090945125\n",
            "Validation Accuracy after epoch 37: 71.61%\n",
            "Epoch: 38, Training Loss: 0.5010082612333395\n",
            "Validation Accuracy after epoch 38: 71.99%\n",
            "Epoch: 39, Training Loss: 0.48448668629921915\n",
            "Validation Accuracy after epoch 39: 70.84%\n",
            "Epoch: 40, Training Loss: 0.46887226014033606\n",
            "Validation Accuracy after epoch 40: 72.77%\n",
            "Epoch: 41, Training Loss: 0.4514216190142095\n",
            "Validation Accuracy after epoch 41: 71.64%\n",
            "Epoch: 42, Training Loss: 0.43556247474363696\n",
            "Validation Accuracy after epoch 42: 72.48%\n",
            "Epoch: 43, Training Loss: 0.419300809045277\n",
            "Validation Accuracy after epoch 43: 72.26%\n",
            "Epoch: 44, Training Loss: 0.4050668434566244\n",
            "Validation Accuracy after epoch 44: 71.75%\n",
            "Epoch: 45, Training Loss: 0.3882090651889896\n",
            "Validation Accuracy after epoch 45: 71.85000000000001%\n",
            "Epoch: 46, Training Loss: 0.3725495559861288\n",
            "Validation Accuracy after epoch 46: 73.42%\n",
            "Epoch: 47, Training Loss: 0.3574269640514308\n",
            "Validation Accuracy after epoch 47: 72.94%\n",
            "Epoch: 48, Training Loss: 0.34239609899651974\n",
            "Validation Accuracy after epoch 48: 72.43%\n",
            "Epoch: 49, Training Loss: 0.32698961036741886\n",
            "Validation Accuracy after epoch 49: 72.58%\n",
            "Epoch: 50, Training Loss: 0.3122566419717906\n",
            "Validation Accuracy after epoch 50: 73.26%\n",
            "Epoch: 51, Training Loss: 0.297509349520554\n",
            "Validation Accuracy after epoch 51: 72.72999999999999%\n",
            "Epoch: 52, Training Loss: 0.28462057114790773\n",
            "Validation Accuracy after epoch 52: 71.19%\n",
            "Epoch: 53, Training Loss: 0.269909547980103\n",
            "Validation Accuracy after epoch 53: 73.07000000000001%\n",
            "Epoch: 54, Training Loss: 0.2575590756466931\n",
            "Validation Accuracy after epoch 54: 73.83%\n",
            "Epoch: 55, Training Loss: 0.2438181656629533\n",
            "Validation Accuracy after epoch 55: 71.85000000000001%\n",
            "Epoch: 56, Training Loss: 0.23167380378069474\n",
            "Validation Accuracy after epoch 56: 73.53%\n",
            "Epoch: 57, Training Loss: 0.2188439291932851\n",
            "Validation Accuracy after epoch 57: 72.39%\n",
            "Epoch: 58, Training Loss: 0.20701148102769767\n",
            "Validation Accuracy after epoch 58: 73.49%\n",
            "Epoch: 59, Training Loss: 0.19610250380147448\n",
            "Validation Accuracy after epoch 59: 72.6%\n",
            "Epoch: 60, Training Loss: 0.1836839223428227\n",
            "Validation Accuracy after epoch 60: 73.87%\n",
            "Epoch: 61, Training Loss: 0.17407089201709652\n",
            "Validation Accuracy after epoch 61: 73.66%\n",
            "Epoch: 62, Training Loss: 0.16301487615841734\n",
            "Validation Accuracy after epoch 62: 73.33%\n",
            "Epoch: 63, Training Loss: 0.15294440240239549\n",
            "Validation Accuracy after epoch 63: 73.22999999999999%\n",
            "Epoch: 64, Training Loss: 0.14358411267723725\n",
            "Validation Accuracy after epoch 64: 73.55000000000001%\n",
            "Epoch: 65, Training Loss: 0.1348739755018364\n",
            "Validation Accuracy after epoch 65: 72.86%\n",
            "Epoch: 66, Training Loss: 0.12639888232130833\n",
            "Validation Accuracy after epoch 66: 73.65%\n",
            "Epoch: 67, Training Loss: 0.1174607857290055\n",
            "Validation Accuracy after epoch 67: 73.52%\n",
            "Epoch: 68, Training Loss: 0.11031984429701668\n",
            "Validation Accuracy after epoch 68: 73.48%\n",
            "Epoch: 69, Training Loss: 0.10301616332967721\n",
            "Validation Accuracy after epoch 69: 73.61999999999999%\n",
            "Epoch: 70, Training Loss: 0.09609085059417483\n",
            "Validation Accuracy after epoch 70: 73.9%\n",
            "Epoch: 71, Training Loss: 0.09042895690340291\n",
            "Validation Accuracy after epoch 71: 72.87%\n",
            "Epoch: 72, Training Loss: 0.08426565427780913\n",
            "Validation Accuracy after epoch 72: 73.58%\n",
            "Epoch: 73, Training Loss: 0.07921771134447564\n",
            "Validation Accuracy after epoch 73: 73.47%\n",
            "Epoch: 74, Training Loss: 0.07392406404075567\n",
            "Validation Accuracy after epoch 74: 73.75%\n",
            "Epoch: 75, Training Loss: 0.06930547725418797\n",
            "Validation Accuracy after epoch 75: 73.42999999999999%\n",
            "Epoch: 76, Training Loss: 0.06502187395435008\n",
            "Validation Accuracy after epoch 76: 72.32%\n",
            "Epoch: 77, Training Loss: 0.061533701296447946\n",
            "Validation Accuracy after epoch 77: 73.34%\n",
            "Epoch: 78, Training Loss: 0.057280585100717096\n",
            "Validation Accuracy after epoch 78: 73.32%\n",
            "Epoch: 79, Training Loss: 0.05358403696276038\n",
            "Validation Accuracy after epoch 79: 72.11999999999999%\n",
            "Epoch: 80, Training Loss: 0.05089297277562301\n",
            "Validation Accuracy after epoch 80: 73.42999999999999%\n",
            "Epoch: 81, Training Loss: 0.04751820135099427\n",
            "Validation Accuracy after epoch 81: 73.64%\n",
            "Epoch: 82, Training Loss: 0.044981137542125516\n",
            "Validation Accuracy after epoch 82: 73.5%\n",
            "Epoch: 83, Training Loss: 0.04254479458331681\n",
            "Validation Accuracy after epoch 83: 73.42999999999999%\n",
            "Epoch: 84, Training Loss: 0.04025750356914518\n",
            "Validation Accuracy after epoch 84: 73.45%\n",
            "Epoch: 85, Training Loss: 0.03808151909014415\n",
            "Validation Accuracy after epoch 85: 73.53%\n",
            "Epoch: 86, Training Loss: 0.03606585906508862\n",
            "Validation Accuracy after epoch 86: 73.44000000000001%\n",
            "Epoch: 87, Training Loss: 0.03435269939948988\n",
            "Validation Accuracy after epoch 87: 73.57000000000001%\n",
            "Epoch: 88, Training Loss: 0.03257482118018524\n",
            "Validation Accuracy after epoch 88: 73.58%\n",
            "Epoch: 89, Training Loss: 0.031202740843414956\n",
            "Validation Accuracy after epoch 89: 73.65%\n",
            "Epoch: 90, Training Loss: 0.029766476124791844\n",
            "Validation Accuracy after epoch 90: 73.52%\n",
            "Epoch: 91, Training Loss: 0.02847117907069909\n",
            "Validation Accuracy after epoch 91: 73.37%\n",
            "Epoch: 92, Training Loss: 0.027466960776540095\n",
            "Validation Accuracy after epoch 92: 72.99%\n",
            "Epoch: 93, Training Loss: 0.026083964082743504\n",
            "Validation Accuracy after epoch 93: 73.49%\n",
            "Epoch: 94, Training Loss: 0.02489397917157206\n",
            "Validation Accuracy after epoch 94: 73.35000000000001%\n",
            "Epoch: 95, Training Loss: 0.02410115254447436\n",
            "Validation Accuracy after epoch 95: 73.68%\n",
            "Epoch: 96, Training Loss: 0.023128559322232175\n",
            "Validation Accuracy after epoch 96: 73.47%\n",
            "Epoch: 97, Training Loss: 0.022265329552085503\n",
            "Validation Accuracy after epoch 97: 73.59%\n",
            "Epoch: 98, Training Loss: 0.021401575668845946\n",
            "Validation Accuracy after epoch 98: 73.46000000000001%\n",
            "Epoch: 99, Training Loss: 0.02068575921818576\n",
            "Validation Accuracy after epoch 99: 73.64%\n",
            "Epoch: 100, Training Loss: 0.01999956828511089\n",
            "Validation Accuracy after epoch 100: 73.44000000000001%\n",
            "Epoch: 101, Training Loss: 0.019260757914780047\n",
            "Validation Accuracy after epoch 101: 73.17%\n",
            "Epoch: 102, Training Loss: 0.01865886840635858\n",
            "Validation Accuracy after epoch 102: 73.36%\n",
            "Epoch: 103, Training Loss: 0.018088982360142156\n",
            "Validation Accuracy after epoch 103: 73.52%\n",
            "Epoch: 104, Training Loss: 0.017465277958442185\n",
            "Validation Accuracy after epoch 104: 73.57000000000001%\n",
            "Epoch: 105, Training Loss: 0.01692879404705923\n",
            "Validation Accuracy after epoch 105: 73.61999999999999%\n",
            "Epoch: 106, Training Loss: 0.016368336717138433\n",
            "Validation Accuracy after epoch 106: 73.57000000000001%\n",
            "Epoch: 107, Training Loss: 0.015878428359065788\n",
            "Validation Accuracy after epoch 107: 73.53%\n",
            "Epoch: 108, Training Loss: 0.015440527012671732\n",
            "Validation Accuracy after epoch 108: 73.65%\n",
            "Epoch: 109, Training Loss: 0.014989182619196946\n",
            "Validation Accuracy after epoch 109: 73.81%\n",
            "Epoch: 110, Training Loss: 0.014606697647415502\n",
            "Validation Accuracy after epoch 110: 73.61999999999999%\n",
            "Epoch: 111, Training Loss: 0.014182364032186968\n",
            "Validation Accuracy after epoch 111: 73.67%\n",
            "Epoch: 112, Training Loss: 0.01379384872708422\n",
            "Validation Accuracy after epoch 112: 73.68%\n",
            "Epoch: 113, Training Loss: 0.013417715346083388\n",
            "Validation Accuracy after epoch 113: 73.68%\n",
            "Epoch: 114, Training Loss: 0.013099038280318004\n",
            "Validation Accuracy after epoch 114: 73.61%\n",
            "Epoch: 115, Training Loss: 0.012722260436005033\n",
            "Validation Accuracy after epoch 115: 73.74000000000001%\n",
            "Epoch: 116, Training Loss: 0.01242334906504873\n",
            "Validation Accuracy after epoch 116: 73.61%\n",
            "Epoch: 117, Training Loss: 0.012127047892936203\n",
            "Validation Accuracy after epoch 117: 73.54%\n",
            "Epoch: 118, Training Loss: 0.01183923305121853\n",
            "Validation Accuracy after epoch 118: 73.66%\n",
            "Epoch: 119, Training Loss: 0.011587355946264494\n",
            "Validation Accuracy after epoch 119: 73.61999999999999%\n",
            "Epoch: 120, Training Loss: 0.01128824835981402\n",
            "Validation Accuracy after epoch 120: 73.61999999999999%\n",
            "Epoch: 121, Training Loss: 0.011058061067467493\n",
            "Validation Accuracy after epoch 121: 73.52%\n",
            "Epoch: 122, Training Loss: 0.010803426632567135\n",
            "Validation Accuracy after epoch 122: 73.71%\n",
            "Epoch: 123, Training Loss: 0.01051094539134818\n",
            "Validation Accuracy after epoch 123: 73.67%\n",
            "Epoch: 124, Training Loss: 0.010342564526707163\n",
            "Validation Accuracy after epoch 124: 73.72999999999999%\n",
            "Epoch: 125, Training Loss: 0.010135507727365779\n",
            "Validation Accuracy after epoch 125: 73.54%\n",
            "Epoch: 126, Training Loss: 0.009894085739551068\n",
            "Validation Accuracy after epoch 126: 73.72%\n",
            "Epoch: 127, Training Loss: 0.009682047857290797\n",
            "Validation Accuracy after epoch 127: 73.79%\n",
            "Epoch: 128, Training Loss: 0.009470649394075699\n",
            "Validation Accuracy after epoch 128: 73.81%\n",
            "Epoch: 129, Training Loss: 0.009320593885648662\n",
            "Validation Accuracy after epoch 129: 73.74000000000001%\n",
            "Epoch: 130, Training Loss: 0.009128682935238837\n",
            "Validation Accuracy after epoch 130: 73.52%\n",
            "Epoch: 131, Training Loss: 0.008953542302093467\n",
            "Validation Accuracy after epoch 131: 73.56%\n",
            "Epoch: 132, Training Loss: 0.008774142599809924\n",
            "Validation Accuracy after epoch 132: 73.67%\n",
            "Epoch: 133, Training Loss: 0.008605477422752115\n",
            "Validation Accuracy after epoch 133: 73.78%\n",
            "Epoch: 134, Training Loss: 0.008477068953978284\n",
            "Validation Accuracy after epoch 134: 73.53%\n",
            "Epoch: 135, Training Loss: 0.008291313845111663\n",
            "Validation Accuracy after epoch 135: 73.67%\n",
            "Epoch: 136, Training Loss: 0.008134246838059933\n",
            "Validation Accuracy after epoch 136: 73.68%\n",
            "Epoch: 137, Training Loss: 0.008014377714801684\n",
            "Validation Accuracy after epoch 137: 73.63%\n",
            "Epoch: 138, Training Loss: 0.007876802241498762\n",
            "Validation Accuracy after epoch 138: 73.76%\n",
            "Epoch: 139, Training Loss: 0.0077177076022881454\n",
            "Validation Accuracy after epoch 139: 73.69%\n",
            "Epoch: 140, Training Loss: 0.0075918759949996\n",
            "Validation Accuracy after epoch 140: 73.81%\n",
            "Epoch: 141, Training Loss: 0.007445707163342354\n",
            "Validation Accuracy after epoch 141: 73.68%\n",
            "Epoch: 142, Training Loss: 0.007344957622711349\n",
            "Validation Accuracy after epoch 142: 73.76%\n",
            "Epoch: 143, Training Loss: 0.007228890544368083\n",
            "Validation Accuracy after epoch 143: 73.67%\n",
            "Epoch: 144, Training Loss: 0.007110451829567304\n",
            "Validation Accuracy after epoch 144: 73.77%\n",
            "Epoch: 145, Training Loss: 0.006996392889622399\n",
            "Validation Accuracy after epoch 145: 73.76%\n",
            "Epoch: 146, Training Loss: 0.0068870293407622355\n",
            "Validation Accuracy after epoch 146: 73.72999999999999%\n",
            "Epoch: 147, Training Loss: 0.006766080853048131\n",
            "Validation Accuracy after epoch 147: 73.74000000000001%\n",
            "Epoch: 148, Training Loss: 0.006673303546200571\n",
            "Validation Accuracy after epoch 148: 73.78%\n",
            "Epoch: 149, Training Loss: 0.006566287086242834\n",
            "Validation Accuracy after epoch 149: 73.75%\n",
            "Epoch: 150, Training Loss: 0.006471741142149186\n",
            "Validation Accuracy after epoch 150: 73.67%\n",
            "Epoch: 151, Training Loss: 0.006372414669557892\n",
            "Validation Accuracy after epoch 151: 73.77%\n",
            "Epoch: 152, Training Loss: 0.006291115635355739\n",
            "Validation Accuracy after epoch 152: 73.71%\n",
            "Epoch: 153, Training Loss: 0.006196368284120946\n",
            "Validation Accuracy after epoch 153: 73.83999999999999%\n",
            "Epoch: 154, Training Loss: 0.0061070844194616005\n",
            "Validation Accuracy after epoch 154: 73.61999999999999%\n",
            "Epoch: 155, Training Loss: 0.006019140658018839\n",
            "Validation Accuracy after epoch 155: 73.72%\n",
            "Epoch: 156, Training Loss: 0.005926078818726551\n",
            "Validation Accuracy after epoch 156: 73.82%\n",
            "Epoch: 157, Training Loss: 0.005852342506422831\n",
            "Validation Accuracy after epoch 157: 73.72999999999999%\n",
            "Epoch: 158, Training Loss: 0.005764252920349217\n",
            "Validation Accuracy after epoch 158: 73.67%\n",
            "Epoch: 159, Training Loss: 0.0057002621970218045\n",
            "Validation Accuracy after epoch 159: 73.78%\n",
            "Epoch: 160, Training Loss: 0.0056043762283142454\n",
            "Validation Accuracy after epoch 160: 73.76%\n",
            "Epoch: 161, Training Loss: 0.00553336609547953\n",
            "Validation Accuracy after epoch 161: 73.77%\n",
            "Epoch: 162, Training Loss: 0.005467074862776605\n",
            "Validation Accuracy after epoch 162: 73.74000000000001%\n",
            "Epoch: 163, Training Loss: 0.005394539398634259\n",
            "Validation Accuracy after epoch 163: 73.65%\n",
            "Epoch: 164, Training Loss: 0.005337268826575555\n",
            "Validation Accuracy after epoch 164: 73.74000000000001%\n",
            "Epoch: 165, Training Loss: 0.005260256357857829\n",
            "Validation Accuracy after epoch 165: 73.65%\n",
            "Epoch: 166, Training Loss: 0.00519402904937382\n",
            "Validation Accuracy after epoch 166: 73.76%\n",
            "Epoch: 167, Training Loss: 0.005126434264887991\n",
            "Validation Accuracy after epoch 167: 73.7%\n",
            "Epoch: 168, Training Loss: 0.0050612744893711965\n",
            "Validation Accuracy after epoch 168: 73.71%\n",
            "Epoch: 169, Training Loss: 0.005002598163297833\n",
            "Validation Accuracy after epoch 169: 73.68%\n",
            "Epoch: 170, Training Loss: 0.004949695494709551\n",
            "Validation Accuracy after epoch 170: 73.64%\n",
            "Epoch: 171, Training Loss: 0.004881882686358507\n",
            "Validation Accuracy after epoch 171: 73.76%\n",
            "Epoch: 172, Training Loss: 0.004824380870298733\n",
            "Validation Accuracy after epoch 172: 73.8%\n",
            "Epoch: 173, Training Loss: 0.004771702110057559\n",
            "Validation Accuracy after epoch 173: 73.81%\n",
            "Epoch: 174, Training Loss: 0.004715111764931523\n",
            "Validation Accuracy after epoch 174: 73.83%\n",
            "Epoch: 175, Training Loss: 0.004660946450998907\n",
            "Validation Accuracy after epoch 175: 73.77%\n",
            "Epoch: 176, Training Loss: 0.004609581781551242\n",
            "Validation Accuracy after epoch 176: 73.7%\n",
            "Epoch: 177, Training Loss: 0.004544357823974946\n",
            "Validation Accuracy after epoch 177: 73.8%\n",
            "Epoch: 178, Training Loss: 0.004507960165407785\n",
            "Validation Accuracy after epoch 178: 73.8%\n",
            "Epoch: 179, Training Loss: 0.004457108144376836\n",
            "Validation Accuracy after epoch 179: 73.68%\n",
            "Epoch: 180, Training Loss: 0.0044040449682380195\n",
            "Validation Accuracy after epoch 180: 73.75%\n",
            "Epoch: 181, Training Loss: 0.004353498804199574\n",
            "Validation Accuracy after epoch 181: 73.89%\n",
            "Epoch: 182, Training Loss: 0.004311753647423366\n",
            "Validation Accuracy after epoch 182: 73.76%\n",
            "Epoch: 183, Training Loss: 0.004264182069331712\n",
            "Validation Accuracy after epoch 183: 73.7%\n",
            "Epoch: 184, Training Loss: 0.004217714516391211\n",
            "Validation Accuracy after epoch 184: 73.72%\n",
            "Epoch: 185, Training Loss: 0.004170072001471754\n",
            "Validation Accuracy after epoch 185: 73.79%\n",
            "Epoch: 186, Training Loss: 0.004127141211808318\n",
            "Validation Accuracy after epoch 186: 73.75%\n",
            "Epoch: 187, Training Loss: 0.004085807029403213\n",
            "Validation Accuracy after epoch 187: 73.78%\n",
            "Epoch: 188, Training Loss: 0.004045521888388868\n",
            "Validation Accuracy after epoch 188: 73.72999999999999%\n",
            "Epoch: 189, Training Loss: 0.003999243432190269\n",
            "Validation Accuracy after epoch 189: 73.63%\n",
            "Epoch: 190, Training Loss: 0.003959534094755864\n",
            "Validation Accuracy after epoch 190: 73.81%\n",
            "Epoch: 191, Training Loss: 0.003915218449414462\n",
            "Validation Accuracy after epoch 191: 73.74000000000001%\n",
            "Epoch: 192, Training Loss: 0.0038807842156390097\n",
            "Validation Accuracy after epoch 192: 73.71%\n",
            "Epoch: 193, Training Loss: 0.003840602116773615\n",
            "Validation Accuracy after epoch 193: 73.74000000000001%\n",
            "Epoch: 194, Training Loss: 0.0038059225353255124\n",
            "Validation Accuracy after epoch 194: 73.71%\n",
            "Epoch: 195, Training Loss: 0.003774124210464585\n",
            "Validation Accuracy after epoch 195: 73.69%\n",
            "Epoch: 196, Training Loss: 0.0037329379082693126\n",
            "Validation Accuracy after epoch 196: 73.74000000000001%\n",
            "Epoch: 197, Training Loss: 0.003693242778565706\n",
            "Validation Accuracy after epoch 197: 73.86%\n",
            "Epoch: 198, Training Loss: 0.003664395197585244\n",
            "Validation Accuracy after epoch 198: 73.78%\n",
            "Epoch: 199, Training Loss: 0.003626902296078032\n",
            "Validation Accuracy after epoch 199: 73.8%\n",
            "Epoch: 200, Training Loss: 0.0035926104135289693\n",
            "Validation Accuracy after epoch 200: 73.69%\n",
            "Epoch: 201, Training Loss: 0.003563457852988111\n",
            "Validation Accuracy after epoch 201: 73.68%\n",
            "Epoch: 202, Training Loss: 0.003528807866934906\n",
            "Validation Accuracy after epoch 202: 73.82%\n",
            "Epoch: 203, Training Loss: 0.003494299698264941\n",
            "Validation Accuracy after epoch 203: 73.72%\n",
            "Epoch: 204, Training Loss: 0.0034647501269391145\n",
            "Validation Accuracy after epoch 204: 73.8%\n",
            "Epoch: 205, Training Loss: 0.003430769016729225\n",
            "Validation Accuracy after epoch 205: 73.81%\n",
            "Epoch: 206, Training Loss: 0.003397207761801484\n",
            "Validation Accuracy after epoch 206: 73.83999999999999%\n",
            "Epoch: 207, Training Loss: 0.003370501236338645\n",
            "Validation Accuracy after epoch 207: 73.75%\n",
            "Epoch: 208, Training Loss: 0.00334110379884796\n",
            "Validation Accuracy after epoch 208: 73.64%\n",
            "Epoch: 209, Training Loss: 0.0033140330457204804\n",
            "Validation Accuracy after epoch 209: 73.71%\n",
            "Epoch: 210, Training Loss: 0.0032849105606760705\n",
            "Validation Accuracy after epoch 210: 73.77%\n",
            "Epoch: 211, Training Loss: 0.0032576702706649174\n",
            "Validation Accuracy after epoch 211: 73.6%\n",
            "Epoch: 212, Training Loss: 0.0032254306254420155\n",
            "Validation Accuracy after epoch 212: 73.75%\n",
            "Epoch: 213, Training Loss: 0.003196191268346613\n",
            "Validation Accuracy after epoch 213: 73.76%\n",
            "Epoch: 214, Training Loss: 0.003170662208685361\n",
            "Validation Accuracy after epoch 214: 73.79%\n",
            "Epoch: 215, Training Loss: 0.0031441476642954476\n",
            "Validation Accuracy after epoch 215: 73.72999999999999%\n",
            "Epoch: 216, Training Loss: 0.0031216138520675815\n",
            "Validation Accuracy after epoch 216: 73.7%\n",
            "Epoch: 217, Training Loss: 0.003091012587552876\n",
            "Validation Accuracy after epoch 217: 73.67%\n",
            "Epoch: 218, Training Loss: 0.0030652210351598957\n",
            "Validation Accuracy after epoch 218: 73.67%\n",
            "Epoch: 219, Training Loss: 0.003042627261895591\n",
            "Validation Accuracy after epoch 219: 73.76%\n",
            "Epoch: 220, Training Loss: 0.0030193308568107024\n",
            "Validation Accuracy after epoch 220: 73.77%\n",
            "Epoch: 221, Training Loss: 0.0029954289025424614\n",
            "Validation Accuracy after epoch 221: 73.68%\n",
            "Epoch: 222, Training Loss: 0.0029665834880481614\n",
            "Validation Accuracy after epoch 222: 73.7%\n",
            "Epoch: 223, Training Loss: 0.0029434735678038693\n",
            "Validation Accuracy after epoch 223: 73.69%\n",
            "Epoch: 224, Training Loss: 0.00291759483179773\n",
            "Validation Accuracy after epoch 224: 73.77%\n",
            "Epoch: 225, Training Loss: 0.002898968370331218\n",
            "Validation Accuracy after epoch 225: 73.61%\n",
            "Epoch: 226, Training Loss: 0.0028786268427639324\n",
            "Validation Accuracy after epoch 226: 73.76%\n",
            "Epoch: 227, Training Loss: 0.0028541896806653505\n",
            "Validation Accuracy after epoch 227: 73.64%\n",
            "Epoch: 228, Training Loss: 0.002837197146202197\n",
            "Validation Accuracy after epoch 228: 73.72%\n",
            "Epoch: 229, Training Loss: 0.002810731947170737\n",
            "Validation Accuracy after epoch 229: 73.63%\n",
            "Epoch: 230, Training Loss: 0.002789898965176662\n",
            "Validation Accuracy after epoch 230: 73.83999999999999%\n",
            "Epoch: 231, Training Loss: 0.0027702355497133207\n",
            "Validation Accuracy after epoch 231: 73.66%\n",
            "Epoch: 232, Training Loss: 0.002745494254521759\n",
            "Validation Accuracy after epoch 232: 73.75%\n",
            "Epoch: 233, Training Loss: 0.0027226639850198497\n",
            "Validation Accuracy after epoch 233: 73.81%\n",
            "Epoch: 234, Training Loss: 0.0027070417467271314\n",
            "Validation Accuracy after epoch 234: 73.67%\n",
            "Epoch: 235, Training Loss: 0.002686701582945988\n",
            "Validation Accuracy after epoch 235: 73.68%\n",
            "Epoch: 236, Training Loss: 0.002665131244614311\n",
            "Validation Accuracy after epoch 236: 73.67%\n",
            "Epoch: 237, Training Loss: 0.0026457472146093333\n",
            "Validation Accuracy after epoch 237: 73.71%\n",
            "Epoch: 238, Training Loss: 0.0026285706406228167\n",
            "Validation Accuracy after epoch 238: 73.71%\n",
            "Epoch: 239, Training Loss: 0.00260688893867971\n",
            "Validation Accuracy after epoch 239: 73.72%\n",
            "Epoch: 240, Training Loss: 0.0025881865178532613\n",
            "Validation Accuracy after epoch 240: 73.81%\n",
            "Epoch: 241, Training Loss: 0.002572931198473505\n",
            "Validation Accuracy after epoch 241: 73.71%\n",
            "Epoch: 242, Training Loss: 0.0025551461531599638\n",
            "Validation Accuracy after epoch 242: 73.68%\n",
            "Epoch: 243, Training Loss: 0.0025354977677781087\n",
            "Validation Accuracy after epoch 243: 73.71%\n",
            "Epoch: 244, Training Loss: 0.0025179567316587527\n",
            "Validation Accuracy after epoch 244: 73.72999999999999%\n",
            "Epoch: 245, Training Loss: 0.0024967854235159316\n",
            "Validation Accuracy after epoch 245: 73.67%\n",
            "Epoch: 246, Training Loss: 0.00248405021672492\n",
            "Validation Accuracy after epoch 246: 73.7%\n",
            "Epoch: 247, Training Loss: 0.0024672549853906453\n",
            "Validation Accuracy after epoch 247: 73.63%\n",
            "Epoch: 248, Training Loss: 0.0024478477536036118\n",
            "Validation Accuracy after epoch 248: 73.64%\n",
            "Epoch: 249, Training Loss: 0.0024342752410732495\n",
            "Validation Accuracy after epoch 249: 73.68%\n",
            "Epoch: 250, Training Loss: 0.00241495847828267\n",
            "Validation Accuracy after epoch 250: 73.72%\n",
            "Epoch: 251, Training Loss: 0.0023979220391653687\n",
            "Validation Accuracy after epoch 251: 73.74000000000001%\n",
            "Epoch: 252, Training Loss: 0.002382737504023001\n",
            "Validation Accuracy after epoch 252: 73.66%\n",
            "Epoch: 253, Training Loss: 0.0023682297733219346\n",
            "Validation Accuracy after epoch 253: 73.75%\n",
            "Epoch: 254, Training Loss: 0.002351223790060605\n",
            "Validation Accuracy after epoch 254: 73.63%\n",
            "Epoch: 255, Training Loss: 0.0023346978769389925\n",
            "Validation Accuracy after epoch 255: 73.66%\n",
            "Epoch: 256, Training Loss: 0.0023213575980888055\n",
            "Validation Accuracy after epoch 256: 73.7%\n",
            "Epoch: 257, Training Loss: 0.0023042490092359835\n",
            "Validation Accuracy after epoch 257: 73.69%\n",
            "Epoch: 258, Training Loss: 0.0022899637514156054\n",
            "Validation Accuracy after epoch 258: 73.67%\n",
            "Epoch: 259, Training Loss: 0.0022765492720891486\n",
            "Validation Accuracy after epoch 259: 73.69%\n",
            "Epoch: 260, Training Loss: 0.002260224198918942\n",
            "Validation Accuracy after epoch 260: 73.69%\n",
            "Epoch: 261, Training Loss: 0.0022472041211557834\n",
            "Validation Accuracy after epoch 261: 73.69%\n",
            "Epoch: 262, Training Loss: 0.0022329612833964624\n",
            "Validation Accuracy after epoch 262: 73.61%\n",
            "Epoch: 263, Training Loss: 0.002217614490454278\n",
            "Validation Accuracy after epoch 263: 73.68%\n",
            "Epoch: 264, Training Loss: 0.0022031758866353853\n",
            "Validation Accuracy after epoch 264: 73.61999999999999%\n",
            "Epoch: 265, Training Loss: 0.0021908780303247785\n",
            "Validation Accuracy after epoch 265: 73.65%\n",
            "Epoch: 266, Training Loss: 0.0021751634225778073\n",
            "Validation Accuracy after epoch 266: 73.72%\n",
            "Epoch: 267, Training Loss: 0.0021628831204174616\n",
            "Validation Accuracy after epoch 267: 73.69%\n",
            "Epoch: 268, Training Loss: 0.002148152569822772\n",
            "Validation Accuracy after epoch 268: 73.59%\n",
            "Epoch: 269, Training Loss: 0.002135312284284588\n",
            "Validation Accuracy after epoch 269: 73.66%\n",
            "Epoch: 270, Training Loss: 0.0021246419309952852\n",
            "Validation Accuracy after epoch 270: 73.64%\n",
            "Epoch: 271, Training Loss: 0.0021088595857576982\n",
            "Validation Accuracy after epoch 271: 73.69%\n",
            "Epoch: 272, Training Loss: 0.0020983095526161707\n",
            "Validation Accuracy after epoch 272: 73.68%\n",
            "Epoch: 273, Training Loss: 0.002085656563029684\n",
            "Validation Accuracy after epoch 273: 73.72999999999999%\n",
            "Epoch: 274, Training Loss: 0.0020724982986419613\n",
            "Validation Accuracy after epoch 274: 73.68%\n",
            "Epoch: 275, Training Loss: 0.0020608543962462927\n",
            "Validation Accuracy after epoch 275: 73.67%\n",
            "Epoch: 276, Training Loss: 0.002048816734506889\n",
            "Validation Accuracy after epoch 276: 73.72%\n",
            "Epoch: 277, Training Loss: 0.002035342054018784\n",
            "Validation Accuracy after epoch 277: 73.61999999999999%\n",
            "Epoch: 278, Training Loss: 0.0020247233474491367\n",
            "Validation Accuracy after epoch 278: 73.68%\n",
            "Epoch: 279, Training Loss: 0.0020122642024739375\n",
            "Validation Accuracy after epoch 279: 73.68%\n",
            "Epoch: 280, Training Loss: 0.0019990695697610335\n",
            "Validation Accuracy after epoch 280: 73.6%\n",
            "Epoch: 281, Training Loss: 0.0019880530799267445\n",
            "Validation Accuracy after epoch 281: 73.66%\n",
            "Epoch: 282, Training Loss: 0.001978354229692422\n",
            "Validation Accuracy after epoch 282: 73.71%\n",
            "Epoch: 283, Training Loss: 0.001965819360495395\n",
            "Validation Accuracy after epoch 283: 73.66%\n",
            "Epoch: 284, Training Loss: 0.0019537895646058213\n",
            "Validation Accuracy after epoch 284: 73.7%\n",
            "Epoch: 285, Training Loss: 0.0019437136394126564\n",
            "Validation Accuracy after epoch 285: 73.69%\n",
            "Epoch: 286, Training Loss: 0.001933110589215108\n",
            "Validation Accuracy after epoch 286: 73.53%\n",
            "Epoch: 287, Training Loss: 0.0019218509860784577\n",
            "Validation Accuracy after epoch 287: 73.68%\n",
            "Epoch: 288, Training Loss: 0.001911948888239277\n",
            "Validation Accuracy after epoch 288: 73.59%\n",
            "Epoch: 289, Training Loss: 0.001899141749061044\n",
            "Validation Accuracy after epoch 289: 73.66%\n",
            "Epoch: 290, Training Loss: 0.0018903166820120085\n",
            "Validation Accuracy after epoch 290: 73.68%\n",
            "Epoch: 291, Training Loss: 0.0018788936310191698\n",
            "Validation Accuracy after epoch 291: 73.67%\n",
            "Epoch: 292, Training Loss: 0.0018694800774470362\n",
            "Validation Accuracy after epoch 292: 73.67%\n",
            "Epoch: 293, Training Loss: 0.0018600730932272417\n",
            "Validation Accuracy after epoch 293: 73.72999999999999%\n",
            "Epoch: 294, Training Loss: 0.0018483585076015966\n",
            "Validation Accuracy after epoch 294: 73.63%\n",
            "Epoch: 295, Training Loss: 0.001838397732197457\n",
            "Validation Accuracy after epoch 295: 73.64%\n",
            "Epoch: 296, Training Loss: 0.0018286927039866023\n",
            "Validation Accuracy after epoch 296: 73.68%\n",
            "Epoch: 297, Training Loss: 0.0018205964277424585\n",
            "Validation Accuracy after epoch 297: 73.74000000000001%\n",
            "Epoch: 298, Training Loss: 0.0018103793361688705\n",
            "Validation Accuracy after epoch 298: 73.69%\n",
            "Epoch: 299, Training Loss: 0.0017977811613023671\n",
            "Validation Accuracy after epoch 299: 73.65%\n",
            "Epoch: 300, Training Loss: 0.0017898496777942294\n",
            "Validation Accuracy after epoch 300: 73.7%\n",
            "Total Training Time: 11.862841844558716 seconds\n"
          ]
        }
      ]
    }
  ]
}
