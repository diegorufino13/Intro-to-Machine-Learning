{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import time\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "MKTeZhS72w7l"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data to tensor\n",
        "data_path = '../data-unversions/p1ch7/'\n",
        "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download = True , transform=transforms.ToTensor())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfDIQZT70oUI",
        "outputId": "c4b28fc4-0223-4e48-d56d-9fc1286258be"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Image Data\n",
        "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)\n",
        "mean = imgs.view(3, -1).mean(dim=1)\n",
        "std = imgs.view(3, -1).std(dim=1)\n",
        "normalization = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)])"
      ],
      "metadata": {
        "id": "30Gg7t3O3BkS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1Nh8s75x5n2",
        "outputId": "76831712-05f4-4706-ba64-d06ed6680aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.CIFAR10(root= data_path, train=True, download = True, transform=normalization)\n",
        "cifar10_train = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "valid_data = datasets.CIFAR10(root= data_path, train=False, download = True, transform=normalization)\n",
        "cifar10_valid = torch.utils.data.DataLoader(valid_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "IY0TU1Ya6IC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_data, valid_data):\n",
        "  for epoch in range(n_epochs+1):\n",
        "    for imgs, labels in train_data:\n",
        "      batch = imgs.shape[0]\n",
        "      out = model(imgs.view(batch,-1))\n",
        "      loss_train = loss_fn(out, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "      print(\"Epoch: %d, Training Loss: %f\" % (epoch, float(loss_train)))\n",
        "  trainStop = time.time()\n",
        "  trainDuration = trainStop - trainStart\n",
        "\n",
        "  print(f'Total Training Time: {trainDuration} seconds')\n",
        "\n",
        "  total = 0\n",
        "  correctClass = 0\n",
        "  validStart = time.time()\n",
        "  with torch.no_grad():\n",
        "    for imgs, labels in valid_data:\n",
        "      batch = imgs.shape[0]\n",
        "      out = model(imgs.view(batch, -1))\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      total += labels.shape[0]\n",
        "      correctClass += int((predicted == labels).sum())\n",
        "\n",
        "  validStop = time.time()\n",
        "  validDuration = validStop - validStart\n",
        "\n",
        "  print(f'\\nValidation Accuracy: {(correctClass/total) * 100}%')\n",
        "  print(f'Total Validation Time: {validDuration} seconds')\n",
        "  print(f'Total Runtime: {trainDuration + validDuration} seconds')\n"
      ],
      "metadata": {
        "id": "qhj4p5ij0NyL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1a"
      ],
      "metadata": {
        "id": "RD-934AGcfqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model = nn.Sequential(\n",
        "    nn.Linear(3072, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10))\n",
        "\n",
        "optimizer = optim.SGD(seq_model.parameters(), lr = 0.01)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = seq_model,\n",
        "    loss_fn = nn.CrossEntropyLoss(),\n",
        "    train_data = cifar10_train,\n",
        "    valid_data = cifar10_valid\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkEOk_R60SS7",
        "outputId": "7c5f3735-ce15-471e-fd8f-91d4c9f82c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Training Loss: 2.430470\n",
            "Epoch: 50, Training Loss: 1.900788\n",
            "Epoch: 100, Training Loss: 1.971840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1b"
      ],
      "metadata": {
        "id": "NPSkSaWjc0T6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model = nn.Sequential(\n",
        "    nn.Linear(3072, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256,10))\n",
        "\n",
        "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3)\n",
        "\n",
        "training(\n",
        "    epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = seq_model,\n",
        "    loss_fn = nn.CrossEntropyLoss(),\n",
        "    train_data = cifar10_train,\n",
        "    valid_data = cifar10_valid\n",
        ")"
      ],
      "metadata": {
        "id": "AoBo3okP0Vxb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}